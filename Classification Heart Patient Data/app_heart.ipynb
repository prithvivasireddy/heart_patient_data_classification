{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d1ddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app_heart.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_heart.py\n",
    "\n",
    "# Snowpark\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import avg, sum, col,lit, as_double\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from streamlit_option_menu import option_menu\n",
    "import json\n",
    "\n",
    "# Create Session object\n",
    "def create_session_object():\n",
    "    \n",
    "    with open('creds.json') as f:\n",
    "        connection_parameters = json.load(f) \n",
    "    \n",
    "    session = Session.builder.configs(connection_parameters).create()\n",
    "    print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())\n",
    "    return session\n",
    "\n",
    "\n",
    "def train (session, table, model, cwh, cwh_size, use_optimized):\n",
    "\n",
    "    if (use_optimized):\n",
    "        cmd = \"alter warehouse \" + cwh + \" suspend\"\n",
    "        session.sql(cmd).collect()\n",
    "    \n",
    "        cmd = \"alter warehouse \" + cwh + \" set warehouse_size = '2X-Large'\"\n",
    "        session.sql(cmd).collect()\n",
    "    \n",
    "        cmd = \"alter warehouse \" + cwh + \" set WAREHOUSE_TYPE = 'SNOWPARK-OPTIMIZED'\"\n",
    "        session.sql(cmd).collect()\n",
    "    \n",
    "    model_name = str.replace(model, ' ', '_')\n",
    "    session.call('internal.sf_scaler_train',model, table, \n",
    "                 '@models', model_name, 'schema=2')\n",
    "\n",
    "    if (use_optimized):\n",
    "        cmd = \"alter warehouse \" + cwh + \" suspend\"\n",
    "        session.sql(cmd).collect()\n",
    "    \n",
    "        cmd = \"alter warehouse \" + cwh + \" set WAREHOUSE_TYPE = 'STANDARD'\"\n",
    "        session.sql(cmd).collect()\n",
    "\n",
    "        cmd = \"alter warehouse \" + cwh + \" set warehouse_size = '\" + cwh_size + \"'\"\n",
    "        session.sql(cmd).collect()\n",
    "\n",
    "\n",
    "def score (session, table_orig, model_name, target_table, cwh, cwh_size, size_wh):\n",
    "\n",
    "    cmd = \"alter warehouse \" + cwh + \" set warehouse_size = '\" + size_wh + \"'\"\n",
    "    session.sql(cmd).collect()\n",
    "    \n",
    "    session.call('internal.sf_score', table_orig, target_table, '@models', model_name )\n",
    " \n",
    "    cmd = \"alter warehouse \" + cwh + \" set warehouse_size = '\" + cwh_size + \"'\"\n",
    "    session.sql(cmd).collect()\n",
    "\n",
    "    \n",
    "def copy_into (session, list_files, table_name):\n",
    "\n",
    "    session.call('internal.copy_into', list_files, table_name)\n",
    "\n",
    "    \n",
    "def to_pct(value):\n",
    "    \n",
    "    val1= (float(value) * 100)\n",
    "    val2 = f'{val1:.2f}'\n",
    "    \n",
    "    return val2 + \" %\"\n",
    "\n",
    "#########################################\n",
    "##### MAIN STREAMLIT APP STARTS HERE ####\n",
    "#########################################\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"HPD Classification\",page_icon=\"❄️\")\n",
    "\n",
    "# Add header and a subheader\n",
    "st.header(\"Classification Heart Patient Data\")\n",
    "\n",
    "session = create_session_object()\n",
    "\n",
    "with st.sidebar:\n",
    "    option = option_menu(\"Snowpark Classification Demo\", [\"Load Data\", \"Analyze\", \"Train Model\", \"Model Catalog\",\n",
    "                                                            \"Inference\", \"Inference Runs\"],\n",
    "                            icons=['upload','graph-up', 'play-circle','list-task', 'boxes', 'speedometer2'],\n",
    "                            menu_icon=\"snow\", default_index=0,\n",
    "                            styles={\n",
    "            \"container\": {\"padding\": \"5!important\", \"background-color\": \"white\",\"font-color\": \"#249dda\"},\n",
    "            \"icon\": {\"color\": \"#31c0e7\", \"font-size\": \"25px\"}, \n",
    "            \"nav-link\": {\"font-size\": \"16px\", \"text-align\": \"left\", \"margin\":\"0px\", \"--hover-color\": \"white\"},\n",
    "            \"nav-link-selected\": {\"background-color\": \"7734f9\"},\n",
    "        })\n",
    "\n",
    "if option == \"Load Data\":\n",
    "    \n",
    "    data_load = session.sql('ls @internal.load_data').collect()\n",
    "\n",
    "    st.markdown('----')\n",
    "    st.subheader(\"Data Loading\")\n",
    "    \n",
    "    col_files, col_name_table = st.columns(2)\n",
    "\n",
    "    with st.container():\n",
    "        with col_files:    # data loading\n",
    "            list_files = []\n",
    "            files_available = session.sql(\"ls @internal.load_data\").collect()\n",
    "            for f in files_available:\n",
    "                list_files.append(f[\"name\"])\n",
    "                            \n",
    "            files = st.selectbox('Load data to train your models:',\n",
    "                    list_files)\n",
    "  \n",
    "            st.write('Files to load:', files)\n",
    "\n",
    "        with col_name_table:\n",
    "            table_name = st.text_input (\"Table name to be created:\", value=\"DEFAULT\")\n",
    "            st.write('Table to be created:', table_name)\n",
    "\n",
    "            \n",
    "        files = \"@\" + files\n",
    "        st.button('Load Data', on_click=copy_into, args=(session, files, table_name))\n",
    "\n",
    "    st.markdown('----')\n",
    "  \n",
    "elif option == \"Analyze\":\n",
    "\n",
    "    st.markdown('----')\n",
    "    with st.container():\n",
    "        df_tables = session.table('information_schema.tables').filter(col(\"table_schema\") == 'DATA').select(col(\"table_name\"), col(\"row_count\"), col(\"created\"))\n",
    "        pd_tables = df_tables.to_pandas()\n",
    "        \n",
    "        st.subheader('Tables available:')\n",
    "        st.dataframe(pd_tables)\n",
    "        \n",
    "    with st.container():\n",
    "        \n",
    "        list_tables_names = pd_tables[\"TABLE_NAME\"].values.tolist()\n",
    "        table_to_print = st.selectbox(\"Select table to describe statistics:\", list_tables_names)\n",
    "        \n",
    "        if (table_to_print):\n",
    "            table_to_print = \"DATA.\" + table_to_print\n",
    "        \n",
    "            df_table = session.table(table_to_print)\n",
    "\n",
    "            pd_table = df_table.limit(3).to_pandas()\n",
    "            pd_describe = df_table.describe().to_pandas()\n",
    "    \n",
    "            col1, col2 = st.columns(2)\n",
    "            with st.container():\n",
    "                with col1:\n",
    "                    positive = df_table.filter(col('target') == 1).count()\n",
    "                    st.metric(label=\"Positive\", value=positive)\n",
    "\n",
    "                with col2:                \n",
    "                    negative = df_table.filter(col('target') == 0).count()\n",
    "                    st.metric(label=\"Negative\", value=negative)\n",
    "            \n",
    "            with st.container():\n",
    "                st.subheader(table_to_print)\n",
    "                st.dataframe(pd_table)\n",
    "        \n",
    "            with st.container():\n",
    "                st.subheader('Data Description')\n",
    "                st.dataframe(pd_describe)\n",
    "\n",
    "elif option == \"Train Model\":\n",
    "    \n",
    "    with st.container():\n",
    "        df_tables = session.table('information_schema.tables').filter(col(\"table_schema\") == 'DATA').select(col(\"table_name\"))\n",
    "        pd_tables = df_tables.to_pandas()\n",
    "        \n",
    "        list_tables_names = pd_tables[\"TABLE_NAME\"].values.tolist()\n",
    "        table_to_train = st.selectbox(\"Select table to train model:\", list_tables_names)\n",
    "        \n",
    "        if (table_to_train):\n",
    "            table_to_train = \"DATA.\" + table_to_train\n",
    "\n",
    "            with st.container():\n",
    "                st.text(\"Table selected: \" + table_to_train)\n",
    "\n",
    "            with st.container():\n",
    "                \n",
    "                \n",
    "                df_models = session.table('internal.models').select(col(\"model_name\"))\n",
    "                pd_models = df_models.to_pandas()\n",
    "                    \n",
    "                model_option = st.selectbox('Choose method for training:', pd_models)\n",
    "                if (model_option):\n",
    "                    st.write ('Model selected: ', model_option)\n",
    "                \n",
    "                    cwh = session.sql(\"select current_warehouse()\").collect()\n",
    "                    cwh = str(cwh[0])\n",
    "                    cwh = cwh.replace(\"CURRENT_WAREHOUSE\",\"\").replace(\")\", \"\").replace(\"Row((=\",\"\")\\\n",
    "                                .replace(\"'\",\"\")\n",
    "\n",
    "                    cmd = \"show warehouses like '\" + cwh + \"'\"\n",
    "                    cwh_size = session.sql(cmd).collect()\n",
    "                    cwh_size = cwh_size[0][\"size\"]\n",
    "                     \n",
    "                    col1, col2 = st.columns(2)\n",
    "                    with st.container():\n",
    "                        with col1:\n",
    "                            use_optimized = st.checkbox('Use Optimized Warehouse for Large Trainings')\n",
    "                        with col2:\n",
    "                            st.button('Train Model', on_click=train, args=(session, table_to_train, \n",
    "                                        model_option, cwh, cwh_size, use_optimized))\n",
    " \n",
    "\n",
    "        st.markdown('----')\n",
    "           \n",
    "elif option == \"Model Catalog\":\n",
    "    \n",
    "    with st.container():\n",
    "  \n",
    "        df_accuracy = session.table('internal.accuracy_sum_v')\n",
    "        pd_accuracy = df_accuracy.to_pandas()\n",
    "\n",
    "        st.subheader('Models Catalog')\n",
    "        st.dataframe(pd_accuracy)       \n",
    "        \n",
    "    with st.container():\n",
    "        df_top = df_accuracy.select(col(\"MODEL_NAME\"), as_double(col(\"ACCURACY\")).alias(\"ACCURACY\")).sort(col(\"ACCURACY\"), ascending=False).limit(5)\n",
    "        pd_top = df_top.to_pandas()\n",
    "        \n",
    "        pd_top.set_index(\"MODEL_NAME\", inplace = True)\n",
    "        st.bar_chart(pd_top)\n",
    "        \n",
    "    \n",
    "    with st.container():\n",
    "    \n",
    "        list_models = pd_accuracy[\"MODEL_NAME\"]\n",
    "        \n",
    "        model = st.selectbox('Choose model for details:', list_models)\n",
    "        \n",
    "        pd_model = session.table('internal.class_report_sumary_v')\\\n",
    "                    .filter(col(\"MODEL_NAME\") == model)\\\n",
    "                    .to_pandas()\n",
    "                \n",
    "        col1, col2 = st.columns(2)\n",
    "        with st.container():\n",
    "            with col1:\n",
    "                st.text(pd_model[\"MODEL_NAME\"].values[0])\n",
    "            with col2:\n",
    "                st.text(pd_model[\"DATA_TRAINING\"].values[0])\n",
    "        \n",
    "        st.markdown('----')\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        with st.container():\n",
    "            with col1:\n",
    "                st.metric(label=\"True Positive\", value=pd_model[\"TP\"])\n",
    "            with col2:\n",
    "                st.metric(label=\"False Positive\", value=pd_model[\"FP\"])\n",
    "\n",
    "        with st.container():\n",
    "            with col1:\n",
    "                 st.metric(label=\"False Negative\", value=pd_model[\"FN\"])            \n",
    "            with col2:\n",
    "                 st.metric(label=\"True Negative\", value=pd_model[\"TN\"])\n",
    "               \n",
    "            \n",
    "        st.markdown('----')\n",
    "\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        with st.container():\n",
    "            with col1:\n",
    "                st.metric(label=\"Negative F1 Score\", value=to_pct(pd_model[\"NEG_F1_SCORE\"].values[0]))\n",
    "            with col2:\n",
    "                st.metric(label=\"Negative Precision\", value=to_pct(pd_model[\"NEG_PRECISION\"].values[0]))\n",
    "            with col3:\n",
    "                st.metric(label=\"Negative Recall\", value=to_pct(pd_model[\"NEG_RECALL\"].values[0]))\n",
    "\n",
    "        with st.container():\n",
    "            with col1:\n",
    "                st.metric(label=\"Positive F1 Score\", value=to_pct(pd_model[\"POS_F1_SCORE\"].values[0]))\n",
    "            with col2:\n",
    "                st.metric(label=\"Positive Precision\", value=to_pct(pd_model[\"POS_PRECISION\"].values[0]))\n",
    "            with col3:\n",
    "                st.metric(label=\"Positive Recall\", value=to_pct(pd_model[\"POS_RECALL\"].values[0]))\n",
    "        \n",
    "        with st.container():\n",
    "            st.metric(label=\"Accuracy\", value=to_pct(pd_model[\"ACCURACY\"].values[0]))\n",
    "\n",
    "elif option == \"Inference\":\n",
    "    st.markdown('----')\n",
    "    \n",
    "    cwh = session.sql(\"select current_warehouse()\").collect()\n",
    "    cwh = str(cwh[0])\n",
    "    cwh = cwh.replace(\"CURRENT_WAREHOUSE\",\"\").replace(\")\", \"\").replace(\"Row((=\",\"\")\\\n",
    "                .replace(\"'\",\"\")\n",
    "\n",
    "    cmd = \"show warehouses like '\" + cwh + \"'\"\n",
    "    cwh_size = session.sql(cmd).collect()\n",
    "    cwh_size = cwh_size[0][\"size\"]\n",
    "    \n",
    "    col_select_model, col_select_table, col_target_table = st.columns(3)\n",
    "    \n",
    "    with st.container():\n",
    "        with col_select_model:\n",
    "            df_accuracy = session.table('internal.accuracy_sum_v')\n",
    "            pd_accuracy = df_accuracy.to_pandas()\n",
    "\n",
    "            list_models = pd_accuracy[\"MODEL_NAME\"].values.tolist()\n",
    "            model_name = st.selectbox(\"Select Model for Inference:\", list_models)\n",
    "\n",
    "        if (model_name):\n",
    "            with col_select_table:\n",
    "                df_tables = session.table('information_schema.tables').filter(col(\"table_schema\") == 'DATA').select(col(\"table_name\"), col(\"row_count\"), col(\"created\"))\n",
    "                pd_tables = df_tables.to_pandas()\n",
    "                list_tables = pd_tables[\"TABLE_NAME\"].values.tolist()\n",
    "\n",
    "                table_orig = st.selectbox(\"Select Table for Inference:\", list_tables)\n",
    "\n",
    "            with col_target_table:\n",
    "                if (model_name != \"\") & (table_orig != \"\"):\n",
    "                    def_output_value = model_name + \"_\" + table_orig + \"_INFERENCE\"\n",
    "                else:\n",
    "                    def_output_value = \"OUTPUT\"\n",
    "                target_table = st.text_input (\"Name output table:\", value=def_output_value)\n",
    "            \n",
    "            col1, col2 = st.columns(2)\n",
    "            with st.container():\n",
    "                with col1:\n",
    "                    size_wh = 'X-Small'\n",
    "                    size_wh = st.selectbox(\"Select WH size:\", ['X-Small', 'Small', 'Medium',\n",
    "                                                    'Large', 'X-Large', '2X-Large'])\n",
    "                with col2: \n",
    "                    st.button('Inference', on_click=score, args=((session, table_orig,\n",
    "                                    model_name, target_table, cwh, cwh_size, size_wh)))\n",
    "\n",
    "elif option == \"Inference Runs\":\n",
    "\n",
    "    with st.container():\n",
    "        df_inference_runs = session.table('internal.inference_runs')\n",
    "        pd_inference_runs = df_inference_runs.to_pandas()\n",
    "        \n",
    "        st.dataframe(pd_inference_runs)\n",
    "    st.markdown('----')\n",
    "\n",
    "    with st.container():\n",
    "        \n",
    "        df_inference_list = df_inference_runs.select(col(\"TARGET_TABLE\"))\n",
    "        pd_inference_list = df_inference_list.to_pandas()\n",
    "        \n",
    "        table_inference = st.selectbox(\"Select Inference Table for Details:\", pd_inference_list)\n",
    "        \n",
    "        if (table_inference):\n",
    "            df_detail_inference = df_inference_runs.filter(col(\"TARGET_TABLE\") == table_inference)\n",
    "            pd_detail_inference = df_detail_inference.to_pandas()\n",
    "        \n",
    "            col1, col2 = st.columns(2)\n",
    "            with st.container():\n",
    "                with col1:\n",
    "                    st.metric(label=\"True Positive\", value=pd_detail_inference[\"TP\"])\n",
    "                with col2:\n",
    "                    st.metric(label=\"False Positive\", value=pd_detail_inference[\"FP\"])\n",
    "\n",
    "            with st.container():\n",
    "                with col1:\n",
    "                     st.metric(label=\"False Negative\", value=pd_detail_inference[\"FN\"])            \n",
    "                with col2:\n",
    "                     st.metric(label=\"True Negative\", value=pd_detail_inference[\"TN\"])\n",
    "\n",
    "            st.markdown('----')\n",
    "\n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "            with st.container():\n",
    "                with col1:\n",
    "                    st.metric(label=\"ACCURACY\", value = to_pct(pd_detail_inference[\"ACCURACY\"]) )\n",
    "                with col2:\n",
    "                    st.metric(label=\"PRECISION\", value = to_pct(pd_detail_inference[\"PRECISION\"]) )\n",
    "                with col3:\n",
    "                    st.metric(label=\"RECALL\", value = to_pct(pd_detail_inference[\"RECALL\"]) )\n",
    "                with col4:\n",
    "                    st.metric(label=\"F1_SCORE\", value = to_pct(pd_detail_inference[\"F1_SCORE\"]) )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#if __name__ == \"__main__\":\n",
    "#    session = create_session_object()\n",
    "\n",
    "#   load_data(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0596f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df03a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysnowpark-ml-streamlist",
   "language": "python",
   "name": "pysnowpark-ml-streamlist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
